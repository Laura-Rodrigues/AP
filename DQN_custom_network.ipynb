{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19460f5b-8ba1-46f9-b59f-ce2e8c0df28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lau/.local/lib/python3.8/site-packages/gym/envs/registration.py:555: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/lau/.local/lib/python3.8/site-packages/gym/envs/registration.py:627: UserWarning: \u001b[33mWARN: The environment creator metadata doesn't include `render_modes`, contains: ['render.modes', 'video.frames_per_second']\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "from nes_py.wrappers import JoypadSpace\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
    "import numpy as np \n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0', apply_api_compatibility=True, render_mode=\"human\")\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af8d6d70-4486-466b-b9a1-9c024d60e40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.spaces import Box\n",
    "from gym import Wrapper, ObservationWrapper\n",
    "from gym.wrappers import FrameStack, GrayScaleObservation, ResizeObservation\n",
    "\n",
    "class CustomWrapper(Wrapper):\n",
    "    def reset(self, **kwargs):\n",
    "        kwargs.pop('seed', None)  # Remove the 'seed' argument\n",
    "        kwargs.pop('options', None)  # Remove the 'options' argument\n",
    "        return self.env.reset(**kwargs)\n",
    "\n",
    "# Wrap your environment\n",
    "env = CustomWrapper(env)\n",
    "\n",
    "class SkipFrame(Wrapper):\n",
    "    def __init__(self, env, skip):\n",
    "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
    "        super().__init__(env)\n",
    "        self._skip = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Repeat action, and sum reward\"\"\"\n",
    "        total_reward = 0.0\n",
    "        for i in range(self._skip):\n",
    "            # Accumulate reward and repeat the same action\n",
    "            obs, reward, done, trunk, info = self.env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        return obs, total_reward, done, trunk, info\n",
    "\n",
    "    \n",
    "class RemoveChannelDim(ObservationWrapper):\n",
    "    def observation(self, observation):\n",
    "        return np.squeeze(observation)\n",
    "    \n",
    "# Apply Wrappers to environment\n",
    "env = SkipFrame(env, skip=4)\n",
    "env = GrayScaleObservation(env)\n",
    "env = ResizeObservation(env, shape=84)\n",
    "env = RemoveChannelDim(env)\n",
    "env = FrameStack(env, num_stack=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd0e2bf4-3191-4d21-856e-c89d6ec672d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-10 23:52:40.167243: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-10 23:52:40.212135: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-10 23:52:40.822121: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f340c2cf-05a7-47ec-9819-e721bda0cee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39420877-b03e-4aa1-a9c4-a2df2d9a9ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './dqn/train/'\n",
    "LOG_DIR = './dqn/logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be196ae0-9bb0-4d1d-94bf-66d8f7c9d86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup model saving callback\n",
    "callback = TrainAndLoggingCallback(check_freq=1000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c76edfda-e91d-4cec-9f16-e81a964e3ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from gymnasium import spaces\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "\n",
    "class CustomCNN(BaseFeaturesExtractor):\n",
    "    \"\"\"\n",
    "    :param observation_space: (gym.Space)\n",
    "    :param features_dim: (int) Number of features extracted.\n",
    "        This corresponds to the number of unit for the last layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, observation_space: spaces.Box, features_dim: int = 256):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        # We assume CxHxW images (channels first)\n",
    "        # Re-ordering will be done by pre-preprocessing or wrapper\n",
    "        n_input_channels = observation_space.shape[0]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=n_input_channels, out_channels=32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        # Compute shape by doing one forward pass\n",
    "        with th.no_grad():\n",
    "            n_flatten = self.cnn(\n",
    "                th.as_tensor(observation_space.sample()[None]).float()\n",
    "            ).shape[1]\n",
    "\n",
    "        self.linear = nn.Sequential(nn.Linear(3136, 512),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(512, features_dim))\n",
    "            #nn.Linear(n_flatten, features_dim), nn.ReLU())\n",
    "\n",
    "    def forward(self, observations: th.Tensor) -> th.Tensor:\n",
    "        return self.linear(self.cnn(observations))\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CustomCNN,\n",
    "    features_extractor_kwargs=dict(features_dim=128),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb86b026-0801-4a3f-a731-a9c90e040bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lau/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/home/lau/.local/lib/python3.8/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = DQN('CnnPolicy', env, verbose=1, tensorboard_log=LOG_DIR, learning_rate=0.00001, \n",
    "            policy_kwargs=policy_kwargs, buffer_size=80000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48139e23-5592-4382-a924-24f0e66d714f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./dqn/logs/\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.11e+03 |\n",
      "|    ep_rew_mean      | 1.54e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 88       |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 4443     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.05e+03 |\n",
      "|    ep_rew_mean      | 1.8e+03  |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 90       |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 8435     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.08e+03 |\n",
      "|    ep_rew_mean      | 1.75e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 90       |\n",
      "|    time_elapsed     | 143      |\n",
      "|    total_timesteps  | 12969    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | 1.78e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 86       |\n",
      "|    time_elapsed     | 213      |\n",
      "|    total_timesteps  | 18448    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.07e+03 |\n",
      "|    ep_rew_mean      | 1.82e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 86       |\n",
      "|    time_elapsed     | 246      |\n",
      "|    total_timesteps  | 21350    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.05e+03 |\n",
      "|    ep_rew_mean      | 1.83e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 86       |\n",
      "|    time_elapsed     | 291      |\n",
      "|    total_timesteps  | 25120    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 958      |\n",
      "|    ep_rew_mean      | 1.76e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 86       |\n",
      "|    time_elapsed     | 311      |\n",
      "|    total_timesteps  | 26830    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 945      |\n",
      "|    ep_rew_mean      | 1.82e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 85       |\n",
      "|    time_elapsed     | 352      |\n",
      "|    total_timesteps  | 30229    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 971      |\n",
      "|    ep_rew_mean      | 1.8e+03  |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 85       |\n",
      "|    time_elapsed     | 407      |\n",
      "|    total_timesteps  | 34959    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 988      |\n",
      "|    ep_rew_mean      | 1.78e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 85       |\n",
      "|    time_elapsed     | 460      |\n",
      "|    total_timesteps  | 39512    |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.logger import configure\n",
    "\n",
    "def train_model():\n",
    "    env.reset()\n",
    "    new_logger = configure(LOG_DIR, [\"stdout\", \"csv\"])\n",
    "    # Set new logger \n",
    "    model.set_logger(new_logger)\n",
    "\n",
    "    model.learn(total_timesteps=40000, callback=callback)\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbcd75fa-1b53-4b37-a8cb-d83d9dace552",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('test_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d310d790-3739-412f-951f-fe4d1a3a7e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74de26ad-6af3-4dff-b805-7223ea41142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "model = DQN.load(\"test_model\")\n",
    "obs = env.reset()\n",
    "\n",
    "print(evaluate_policy(model, env, n_eval_episodes=2, deterministic=False, render=True))\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3732799-a499-4a62-83cb-d2b5ac43ebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52991f29-9fd3-42dc-b9eb-9e5cd59a202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"ppo/logs/progress.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d5b1e8-48f5-4294-ac33-b55a9a4d1fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70d5620-5013-454b-b4f2-616f1226061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ypoints = np.array(df['rollout/ep_rew_mean'].to_numpy())\n",
    "plt.plot(ypoints, color = 'b')\n",
    "plt.show()\n",
    "plt.savefig('dqn/dqn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b663d6-613f-4afe-a723-324dc9d4cbcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
